import os
os.environ["STREAMLIT_WATCH_FILE_SYSTEM"] = "false"

import os
import tempfile
import time
import numpy as np
import soundfile as sf
from moviepy.editor import VideoFileClip
from transformers import pipeline, AutoModelForSpeechSeq2Seq, AutoProcessor
import torch
import streamlit as st
from docx import Document
from docx.shared import Pt

# =======================
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
# =======================
device = "cuda" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "openai/whisper-large-v3"
model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype).to(device)
processor = AutoProcessor.from_pretrained(model_id)

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
    return_timestamps=True
)

# =======================
# –§—É–Ω–∫—Ü–∏–∏
# =======================
def convert_mp4_to_mp3(video_path, output_path):
    video = VideoFileClip(video_path)
    video.audio.write_audiofile(output_path, codec='mp3')
    return output_path

def process_audio(file_path, language="ru", progress_callback=None):
    if file_path.endswith(".mp4"):
        temp_mp3_path = file_path.replace(".mp4", ".mp3")
        file_path = convert_mp4_to_mp3(file_path, temp_mp3_path)

    audio_data, sr = sf.read(file_path)

    if len(audio_data.shape) > 1:
        audio_data = np.mean(audio_data, axis=1)

    # –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã
    segment_duration_sec = 30  # 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç
    total_samples = len(audio_data)
    samples_per_segment = sr * segment_duration_sec
    num_segments = int(np.ceil(total_samples / samples_per_segment))

    full_text = ""

    for i in range(num_segments):
        start_sample = i * samples_per_segment
        end_sample = min((i + 1) * samples_per_segment, total_samples)
        segment = audio_data[start_sample:end_sample]

        result = asr_pipeline(
            {"array": segment, "sampling_rate": sr},
            generate_kwargs={"language": language}
        )
        full_text += result["text"] + "\n\n"

        if progress_callback:
            progress_callback(i + 1, num_segments)

    return full_text.strip()

def generate_docx(text: str) -> bytes:
    doc = Document()

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    heading = doc.add_heading("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", level=1)
    heading.alignment = 0  # –ø–æ –ª–µ–≤–æ–º—É –∫—Ä–∞—é

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    paragraph = doc.add_paragraph(text)
    run = paragraph.runs[0]
    font = run.font
    font.name = "Times New Roman"
    font.size = Pt(14)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        doc.save(tmp.name)
        tmp.seek(0)
        docx_bytes = tmp.read()

    return docx_bytes

# =======================
# Streamlit UI
# =======================

st.set_page_config(page_title="Whisper Transcriber", layout="centered")
st.title("üéß Whisper: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ `.mp3`, `.wav` –∏–ª–∏ `.mp4` –∏ –ø–æ–ª—É—á–∏—Ç–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ Word (.docx).")

uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª", type=["mp3", "wav", "mp4"])

language = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ —Ä–µ—á–∏", ["ru", "en", "de", "fr", "es"], index=0)

if uploaded_file is not None:
    st.info("–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as temp_file:
        temp_file.write(uploaded_file.read())
        temp_path = temp_file.name

    progress_bar = st.progress(0, text="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")

    def update_progress(current, total):
        progress = int((current / total) * 100)
        progress_bar.progress(progress, text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ {current} –∏–∑ {total}")

    try:
        start_time = time.time()
        with st.spinner("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è..."):
            transcribed_text = process_audio(temp_path, language, progress_callback=update_progress)

        elapsed = time.time() - start_time
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.strftime('%H:%M:%S', time.gmtime(elapsed))}")

        st.text_area("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ç–µ–∫—Å—Ç–∞", transcribed_text, height=300)

        docx_data = generate_docx(transcribed_text)

        st.download_button(
            label="üìÑ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (.docx)",
            data=docx_data,
            file_name="transcription.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )

    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")

    finally:
        os.remove(temp_path)
